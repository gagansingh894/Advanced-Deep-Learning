{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python36964bite6955f2e74d64707b01ddae88c9da161",
   "display_name": "Python 3.6.9 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('/media/gagandeep/2E92405C92402AA3/Work/Codes/PythonCodes/Advanced-Deep-Learning/Seq_2_Seq_LSTM_Model/translator_model_seq_2_seq_bidirectional.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/media/gagandeep/2E92405C92402AA3/Work/Codes/PythonCodes/Advanced-Deep-Learning/Seq_2_Seq_LSTM_Model/x_tokenizer.pkl', 'rb') as pin:\n",
    "    x_tokenizer = pickle.load(pin)\n",
    "with open('/media/gagandeep/2E92405C92402AA3/Work/Codes/PythonCodes/Advanced-Deep-Learning/Seq_2_Seq_LSTM_Model/y_tokenizer.pkl', 'rb') as pin:\n",
    "    y_tokenizer = pickle.load(pin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Functions\n",
    "# function to obtain the text from padded variables\n",
    "def pad_to_text(padded, tokenizer):\n",
    "\n",
    "    id_to_word = {id: word for word, id in tokenizer.word_index.items()}\n",
    "    id_to_word[0] = ''\n",
    "\n",
    "    return ' '.join([id_to_word[j] for j in padded])\n",
    "\n",
    "# function to make prediction\n",
    "def prediction(x, x_tokenizer = x_tokenizer, y_tokenizer = y_tokenizer):\n",
    "    predictions = model.predict(x)[0]\n",
    "    id_to_word = {id: word for word, id in y_tokenizer.word_index.items()}\n",
    "    id_to_word[0] = ''\n",
    "    return ' '.join([id_to_word[j] for j in np.argmax(predictions,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(5):\n",
    "\n",
    "#   print('Original English word - {}\\n'.format(pad_to_text(x_test[i], x_tokenizer)))\n",
    "#   print('Original French word - {}\\n'.format(pad_to_text(y_test[i], y_tokenizer)))\n",
    "#   print('Predicted French word - {}\\n\\n\\n\\n'.format(prediction(x_test[i:i+1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'la france est parfois occupée en novembre mais il est agréable en mai          '"
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "tst_str = pd.DataFrame({'english':[\"france is sometimes busy during november but it is pleasant in may\"]})\n",
    "tst_seq = pad_sequences(x_tokenizer.texts_to_sequences(tst_str['english']), maxlen=23, padding='post')\n",
    "prediction(tst_seq)"
   ]
  }
 ]
}